{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b99dfd3",
   "metadata": {},
   "source": [
    "# importaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cfa2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b2bf3",
   "metadata": {},
   "source": [
    "# Funciones a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afbd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "def l2_normalize(X: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    n[n == 0] = 1.0\n",
    "    return X / n\n",
    "\n",
    "def cosine_sim(A: np.ndarray, B: np.ndarray) -> np.ndarray:\n",
    "    A_ = l2_normalize(A)\n",
    "    B_ = l2_normalize(B)\n",
    "    return A_ @ B_.T\n",
    "\n",
    "def recall_at_k(ranked_indices, gt_indices, k=10):\n",
    "    hits = 0\n",
    "    for r, gt in zip(ranked_indices, gt_indices):\n",
    "        hits += int(gt in r[:k])\n",
    "    return hits / len(gt_indices)\n",
    "\n",
    "def show_examples(df: pd.DataFrame, idxs, title=\"Ejemplos\"):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    for i in idxs[:5]:\n",
    "        print(f\"[{i}] {df.iloc[i]['Texto']}  ->  {df.iloc[i]['Categoría']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e1aa0",
   "metadata": {},
   "source": [
    "# Carga de dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b108351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10005,\n",
       "                                                Texto Categoría\n",
       " 0       La tokenización es clave para procesar texto  Positivo\n",
       " 1             No entiendo los embeddings vectoriales  Negativo\n",
       " 2         Los LLMs son impresionantes pero complejos   Neutral\n",
       " 3               El curso de NLP es fascinante y útil  Positivo\n",
       " 4  La programación en Python es complicada al pri...  Negativo)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/nlp_prueba_cc0c2_large.csv\")\n",
    "df = df.dropna(subset=[\"Texto\"]).reset_index(drop=True)\n",
    "len(df), df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9f9c6",
   "metadata": {},
   "source": [
    "# Oraciones y Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e8bd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 200\n",
      "\n",
      "--- oraciones ---\n",
      "[0] La tokenización es clave para procesar texto  ->  Positivo\n",
      "[100] La perplejidad parece confuso para procesar texto.  ->  Negativo\n",
      "[500] La lematización requiere fascinante para procesar texto.  ->  Positivo\n",
      "[1000] No entiendo cómo funciona la lematización, es innovador.  ->  Positivo\n",
      "[1500] Implementar regularización se usa para lento en proyectos reales.  ->  Negativo\n",
      "\n",
      "--- consultas ---\n",
      "[0] Los modelos de lenguaje son eficiente pero fascinante.  ->  Positivo\n",
      "[10] Entender los transformers parece eficiente en el curso de NLP.  ->  Positivo\n",
      "[20] No entiendo cómo funciona la lematización, es fundamental.  ->  Neutral\n",
      "[30] Entender los lematización se usa para difícil en el curso de NLP.  ->  Negativo\n",
      "[40] Entender los LLMs se usa para esencial en el curso de NLP.  ->  Positivo\n",
      "Consultas con ground-truth en oraciones: 149 / 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_oraciones = min(8000, len(df) - 200)  \n",
    "n_consultas = 200\n",
    "\n",
    "oraciones  = df.iloc[:n_oraciones].reset_index(drop=True).copy()\n",
    "consultas = df.iloc[n_oraciones:n_oraciones+n_consultas].reset_index(drop=True).copy()\n",
    "\n",
    "print(len(oraciones), len(consultas))\n",
    "show_examples(oraciones, [0, 100, 500, 1000, 1500], \"oraciones\")\n",
    "show_examples(consultas, [0, 10, 20, 30, 40], \"consultas\")\n",
    "\n",
    "\n",
    "texto2idx = {t: i for i, t in enumerate(oraciones[\"Texto\"].tolist())}\n",
    "gt = []\n",
    "mask_has_gt = []\n",
    "for q in consultas[\"Texto\"].tolist():\n",
    "    if q in texto2idx:\n",
    "        gt.append(texto2idx[q])\n",
    "        mask_has_gt.append(True)\n",
    "    else:\n",
    "        gt.append(-1)\n",
    "        mask_has_gt.append(False)\n",
    "\n",
    "valid_mask = np.array(mask_has_gt)\n",
    "print(f\"Consultas con ground-truth en oraciones: {valid_mask.sum()} / {len(consultas)}\")\n",
    "\n",
    "top_k = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd7a87",
   "metadata": {},
   "source": [
    "# TF-IDF RECUPERACION COSENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4a1383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Recall@10: 0.993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    strip_accents=\"unicode\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "Xc = tfidf.fit_transform(oraciones[\"Texto\"].tolist())\n",
    "Xq = tfidf.transform(consultas[\"Texto\"].tolist())\n",
    "\n",
    "\n",
    "Xc_n = normalize(Xc, norm=\"l2\", copy=True)\n",
    "Xq_n = normalize(Xq, norm=\"l2\", copy=True)\n",
    "\n",
    "scores_tfidf = Xq_n @ Xc_n.T       \n",
    "rank_tfidf = np.argsort(-scores_tfidf.toarray(), axis=1)[:, :top_k]\n",
    "\n",
    "recall10_tfidf = recall_at_k(rank_tfidf[valid_mask], np.array(gt)[valid_mask], k=10)\n",
    "print(f\"TF-IDF Recall@10: {recall10_tfidf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eafbea",
   "metadata": {},
   "source": [
    "# EMBEDING DE OREACIONES Y RECUPERACION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59935cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SBERT cargado: paraphrase-multilingual-MiniLM-L12-v2\n",
      "Emb shapes: (8000, 384) (200, 384)\n",
      "Embeddings (paraphrase-multilingual-MiniLM-L12-v2) Recall@10: 0.987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = \"paraphrase-multilingual-MiniLM-L12-v2\"  \n",
    "st_model = SentenceTransformer(MODEL_NAME)\n",
    "print(\"Modelo SBERT cargado:\", MODEL_NAME)\n",
    "\n",
    "\n",
    "emb_corpus = st_model.encode(\n",
    "    oraciones[\"Texto\"].tolist(),\n",
    "    batch_size=64, show_progress_bar=False, normalize_embeddings=True\n",
    ")\n",
    "emb_queries = st_model.encode(\n",
    "    consultas[\"Texto\"].tolist(),\n",
    "    batch_size=64, show_progress_bar=False, normalize_embeddings=True\n",
    ")\n",
    "emb_corpus = np.asarray(emb_corpus)\n",
    "emb_queries = np.asarray(emb_queries)\n",
    "print(\"Emb shapes:\", emb_corpus.shape, emb_queries.shape)\n",
    "\n",
    "S = cosine_sim(emb_queries, emb_corpus)\n",
    "rank_emb = np.argsort(-S, axis=1)[:, :top_k]\n",
    "\n",
    "recall10_emb = recall_at_k(rank_emb[valid_mask], np.array(gt)[valid_mask], k=10)\n",
    "print(f\"Embeddings ({MODEL_NAME}) Recall@10: {recall10_emb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92182b",
   "metadata": {},
   "source": [
    "# COMPARACION RAPIDA Y EJEMPLOS DE VECINOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d1812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen Recall@10 (exact-match, 149 consultas válidas):\n",
      "  TF-IDF   : 0.993\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'emb_backend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResumen Recall@10 (exact-match, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_mask.sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m consultas válidas):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  TF-IDF   : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall10_tfidf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Embeddings (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43memb_backend\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall10_emb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Mostrar vecinos de 3 consultas\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtopn_text\u001b[39m(rank, n=\u001b[32m3\u001b[39m, k=\u001b[32m5\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'emb_backend' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"\\nResumen Recall@10 (exact-match, {valid_mask.sum()} consultas válidas):\")\n",
    "print(f\"  TF-IDF   : {recall10_tfidf:.3f}\")\n",
    "print(f\"  Embeddings ({emb_backend}): {recall10_emb:.3f}\")\n",
    "\n",
    "# Mostrar vecinos de 3 consultas\n",
    "def topn_text(rank, n=3, k=5):\n",
    "    for qi in n:\n",
    "        q_text = consultas.iloc[qi][\"Texto\"]\n",
    "        idxs = rank[qi][:k]\n",
    "        print(\"\\nQ:\", q_text)\n",
    "        for j, di in enumerate(idxs, 1):\n",
    "            print(f\"  {j:2d}) [{di}] {oraciones.iloc[di]['Texto']}\")\n",
    "\n",
    "topn_text(rank_tfidf, n=[0,1,2], k=5)\n",
    "topn_text(rank_emb,   n=[0,1,2], k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a58d70",
   "metadata": {},
   "source": [
    "# PCA 2D EJEMPLOS VECINOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 2D sobre una muestra del corpus (para que sea legible)\n",
    "sample_n = min(1500, emb_corpus.shape[0])\n",
    "idx_s = np.random.choice(emb_corpus.shape[0], size=sample_n, replace=False)\n",
    "Z = emb_corpus[idx_s]\n",
    "\n",
    "pca = PCA(n_components=2, random_state=RNG_SEED)\n",
    "Z2 = pca.fit_transform(Z)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(Z2[:,0], Z2[:,1], s=6, alpha=0.6)\n",
    "plt.title(f\"PCA 2D de embeddings SBERT ({MODEL_NAME})\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/pca_embeddings_2d.png\", dpi=160)\n",
    "plt.show()\n",
    "\n",
    "print(\"Figura guardada en out/pca_embeddings_2d.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb79172",
   "metadata": {},
   "source": [
    "# Variante opcional de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_by_label_at_k(rank, query_labels, corpus_labels, k=10):\n",
    "    hits = 0\n",
    "    for qi, idxs in enumerate(rank):\n",
    "        labs = corpus_labels.iloc[idxs[:k]].tolist()\n",
    "        hits += int(query_labels.iloc[qi] in labs)\n",
    "    return hits / len(query_labels)\n",
    "\n",
    "recall10_tfidf_cat = recall_by_label_at_k(rank_tfidf, consultas[\"Categoría\"], oraciones[\"Categoría\"], k=10)\n",
    "recall10_emb_cat   = recall_by_label_at_k(rank_emb,   consultas[\"Categoría\"], oraciones[\"Categoría\"], k=10)\n",
    "\n",
    "print(f\"TF-IDF  Recall@10 (por categoría): {recall10_tfidf_cat:.3f}\")\n",
    "print(f\"SBERT   Recall@10 (por categoría): {recall10_emb_cat:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632837c2",
   "metadata": {},
   "source": [
    "# Guardar métricas y reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"seed\": RNG_SEED,\n",
    "    \"n_corpus\": int(len(oraciones)),\n",
    "    \"n_queries\": int(len(consultas)),\n",
    "    \"valid_queries_exact_match\": int(valid_mask.sum()),\n",
    "    \"recall10_tfidf_exact\": float(recall10_tfidf),\n",
    "    \"recall10_emb_exact\": float(recall10_emb),\n",
    "    \"recall10_tfidf_by_label\": float(recall10_tfidf_cat),\n",
    "    \"recall10_emb_by_label\": float(recall10_emb_cat),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "}\n",
    "with open(\"out/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Métricas guardadas en out/metrics.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
